{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HyperParameter-with-Raytune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2bbfa24853846c4b2a1b81b9dedbb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_655433b86894425796535cd263b01596",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa9787c6b2e645518c00591a41fe2e90",
              "IPY_MODEL_65063641a7e24de980a71d2ce7ffd56e"
            ]
          }
        },
        "655433b86894425796535cd263b01596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa9787c6b2e645518c00591a41fe2e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9e8a65cf2d946f1be77bb8f51e11753",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3510609e6ac4458c8e5b54e661b8e83e"
          }
        },
        "65063641a7e24de980a71d2ce7ffd56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03c89b26532443b09868fb725f8123c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 112kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0028e5fdbbc9499fa7db601d15d3772f"
          }
        },
        "d9e8a65cf2d946f1be77bb8f51e11753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3510609e6ac4458c8e5b54e661b8e83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03c89b26532443b09868fb725f8123c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0028e5fdbbc9499fa7db601d15d3772f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "844047a7c3ce43fea4ddede2d1e9d0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6218a550ca684714a8ac38df02acedd8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf30bcaa1715405abeb6ecbf5f045cb6",
              "IPY_MODEL_bc286ca608e74166b55c03e52df35015"
            ]
          }
        },
        "6218a550ca684714a8ac38df02acedd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf30bcaa1715405abeb6ecbf5f045cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7cd0ce2613eb4fbab509cbf97bceb0ce",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1c64a313df44f4390e92dde4b5ab399"
          }
        },
        "bc286ca608e74166b55c03e52df35015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_09f8bff5104344c4ba8c8dbdd48af178",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 45.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b8ee7e64327443baef4ebaa56477627"
          }
        },
        "7cd0ce2613eb4fbab509cbf97bceb0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1c64a313df44f4390e92dde4b5ab399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09f8bff5104344c4ba8c8dbdd48af178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b8ee7e64327443baef4ebaa56477627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68a094714eb34bf4b910fd8202fa72f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ddd3944543154e47ae81d9d5833ce038",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8e3e40c28d0453cb71bb0302cb0b921",
              "IPY_MODEL_ba04d27af9b54d389e1791f09b380510"
            ]
          }
        },
        "ddd3944543154e47ae81d9d5833ce038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8e3e40c28d0453cb71bb0302cb0b921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9f713dad4d14ae69e5ecdd1faaf246a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bffa2961e15407a896018b94fa719aa"
          }
        },
        "ba04d27af9b54d389e1791f09b380510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1abd9ea844b4669aded1500fa3d463d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 2.25MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd7a3e74367640f3bd6a1aa991861046"
          }
        },
        "b9f713dad4d14ae69e5ecdd1faaf246a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bffa2961e15407a896018b94fa719aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1abd9ea844b4669aded1500fa3d463d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd7a3e74367640f3bd6a1aa991861046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74d8296c29824624b98c7cf4fdb38dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_157f7cdb25174ac092e6cece32398b2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed45036fbf57429fac491863027099a5",
              "IPY_MODEL_f3367423b72b4c70879f3a7305ebf9d5"
            ]
          }
        },
        "157f7cdb25174ac092e6cece32398b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed45036fbf57429fac491863027099a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80857f4794584a5bb335e26178ae18b7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_390fe4974dff42aebebda4cd33e67288"
          }
        },
        "f3367423b72b4c70879f3a7305ebf9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c16ec2bc47b4db79f41e4b42dff60bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 3.06kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5342847e1d5844f0b897f7ad0db80b6e"
          }
        },
        "80857f4794584a5bb335e26178ae18b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "390fe4974dff42aebebda4cd33e67288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c16ec2bc47b4db79f41e4b42dff60bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5342847e1d5844f0b897f7ad0db80b6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cce37e0a05cb42f5973c807ba701d67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44d8aa8db5c548af98c1d32cc4fe987a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc6c7599793948018315f9c7ba202620",
              "IPY_MODEL_4654e69daeae4ecbb8825c9ca1b33b86"
            ]
          }
        },
        "44d8aa8db5c548af98c1d32cc4fe987a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc6c7599793948018315f9c7ba202620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d0cb292e5424ddb8c63d21c4e233b82",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3db426ac887f44b2938acb307b9705bc"
          }
        },
        "4654e69daeae4ecbb8825c9ca1b33b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d04cabf8221f404dba3cb6cbcd25edc6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 44.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94c6619d6ce546c48f0cdacbea6eb8bf"
          }
        },
        "3d0cb292e5424ddb8c63d21c4e233b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3db426ac887f44b2938acb307b9705bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d04cabf8221f404dba3cb6cbcd25edc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94c6619d6ce546c48f0cdacbea6eb8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Doffcna9jV0w",
        "outputId": "35b86c7f-eb74-42cf-82b7-be1f5d7ad769"
      },
      "source": [
        "pip install ray torch torchvision\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ray\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/d0/33b6f8789cec27ac07e33de987eef9430b211c7d8284437371e45d37bbd5/ray-1.3.0-cp37-cp37m-manylinux2014_x86_64.whl (49.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7MB 61kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting aioredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 10.8MB/s \n",
            "\u001b[?25hCollecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.0.12)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.34.1)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray) (0.10.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n",
            "Collecting redis>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 12.2MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 52.6MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/4d/1a9cbe9a0b543e6733cb38afe26451522a9ef8e4897b59e74cc76838f245/py_spy-0.3.7-py2.py3-none-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1MB 41.1MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.15.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/f8/07b65b1c3a2334208208b8161857fd9c19f69ab5d2c5314ef5f0b5f07aa5/protobuf-3.17.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Collecting opencensus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/59/12044123133d000f705383ad98579aeb0dd82d66b33a254a21b54bf0d6bb/opencensus-0.7.13-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 57.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Collecting async-timeout\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting hiredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/33/290cea35b09c80b4634773ad5572a8030a87b5d39736719f698f521d2a13/hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (1.15.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (5.4.8)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143kB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296kB 59.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (1.26.3)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (20.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (56.1.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.30.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2.4.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.7.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n",
            "Building wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-cp37-none-any.whl size=12621 sha256=2bab8f7f7a61f03ab057c70b831ddba15117d2501e29eb43b7e4e44ad4090de9\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
            "Successfully built gpustat\n",
            "Installing collected packages: colorama, async-timeout, hiredis, aioredis, blessings, gpustat, multidict, yarl, aiohttp, aiohttp-cors, redis, py-spy, protobuf, opencensus-context, opencensus, ray\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "Successfully installed aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 gpustat-0.6.0 hiredis-2.0.0 multidict-5.1.0 opencensus-0.7.13 opencensus-context-0.1.2 protobuf-3.17.1 py-spy-0.3.7 ray-1.3.0 redis-3.5.3 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MuLL4czj-5s",
        "outputId": "b1e06351-43ef-49ff-e474-40bac99d921c"
      },
      "source": [
        "import random\n",
        "from functools import partial\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tensorflow as tf\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, \\\n",
        "      f1_score, precision_score, recall_score, roc_auc_score\n",
        "import pickle\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import metrics\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "  \"update your install command.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnESMpdrk1iR",
        "outputId": "4069d252-e43f-4ec4-feeb-3aa8cb4e80b9"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0FeFJOrk35K",
        "outputId": "4e20cbb4-a4eb-4860-bd13-98748b1eb52d"
      },
      "source": [
        "\n",
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ev-uGeHk6Wp",
        "outputId": "0873b29f-9d58-4a6b-f3b3-646b57116496"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 31.1MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76mu88wbk9Lw",
        "outputId": "96060229-3cbc-48fe-9ead-fa1e3c619111"
      },
      "source": [
        "#this is to load the local data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "921IUUmzlFJq"
      },
      "source": [
        "import pandas as pd\n",
        "def readFile():\n",
        "  dirname = \"seng607/test_negative_roi/Ruby\"\n",
        "  filename = \"Ruby_train.csv\"\n",
        "  f_test = \"Ruby_test.csv\"\n",
        "  df_org = pd.read_csv(\"/content/gdrive/MyDrive/\"+dirname+\"/\"+filename)#, usecols=['req1', 'req2', 'Label'])\n",
        "\n",
        "  df_test = pd.read_csv(\"/content/gdrive/MyDrive/\"+dirname+\"/\"+f_test)#, usecols=['req1', 'req2', 'Label'])\n",
        "  \n",
        "  print(len(df_org), len(df_test))\n",
        "  return df_org, df_test"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2KMaYTNlM2z",
        "outputId": "5d6eec3b-4770-4e8e-824b-e97c0f2f0f25"
      },
      "source": [
        "df, df_test= readFile()\n",
        "print(df)\n",
        "print(df_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1431 361\n",
            "      Unnamed: 0    id1  ... Type of dependency  Label\n",
            "0           3840  10519  ...        independent      0\n",
            "1            973   5749  ...            relates      1\n",
            "2           1440   1411  ...        independent      0\n",
            "3            628  10552  ...            relates      1\n",
            "4           6849  14643  ...        independent      0\n",
            "...          ...    ...  ...                ...    ...\n",
            "1426        1041   5065  ...            relates      1\n",
            "1427         769   8499  ...            relates      1\n",
            "1428           7  17365  ...            relates      1\n",
            "1429        1006  13199  ...            relates      1\n",
            "1430         648  10152  ...            relates      1\n",
            "\n",
            "[1431 rows x 7 columns]\n",
            "     Unnamed: 0    id1  ... Type of dependency  Label\n",
            "0          1172   7022  ...            relates      1\n",
            "1          6987   3547  ...        independent      0\n",
            "2           288  11541  ...            relates      1\n",
            "3          1012  13248  ...            relates      1\n",
            "4          4344  17039  ...        independent      0\n",
            "..          ...    ...  ...                ...    ...\n",
            "356        1098   4247  ...            relates      1\n",
            "357         657  10084  ...            relates      1\n",
            "358         143  11105  ...            relates      1\n",
            "359        9688   3446  ...        independent      0\n",
            "360         432   5749  ...            relates      1\n",
            "\n",
            "[361 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjbxkz0_lRSd"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "def loadBert():\n",
        "  # Load the BERT tokenizer.\n",
        "  print('Loading BERT tokenizer...')\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "  return tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "c2bbfa24853846c4b2a1b81b9dedbb8c",
            "655433b86894425796535cd263b01596",
            "fa9787c6b2e645518c00591a41fe2e90",
            "65063641a7e24de980a71d2ce7ffd56e",
            "d9e8a65cf2d946f1be77bb8f51e11753",
            "3510609e6ac4458c8e5b54e661b8e83e",
            "03c89b26532443b09868fb725f8123c1",
            "0028e5fdbbc9499fa7db601d15d3772f",
            "844047a7c3ce43fea4ddede2d1e9d0a8",
            "6218a550ca684714a8ac38df02acedd8",
            "bf30bcaa1715405abeb6ecbf5f045cb6",
            "bc286ca608e74166b55c03e52df35015",
            "7cd0ce2613eb4fbab509cbf97bceb0ce",
            "d1c64a313df44f4390e92dde4b5ab399",
            "09f8bff5104344c4ba8c8dbdd48af178",
            "6b8ee7e64327443baef4ebaa56477627",
            "68a094714eb34bf4b910fd8202fa72f2",
            "ddd3944543154e47ae81d9d5833ce038",
            "f8e3e40c28d0453cb71bb0302cb0b921",
            "ba04d27af9b54d389e1791f09b380510",
            "b9f713dad4d14ae69e5ecdd1faaf246a",
            "6bffa2961e15407a896018b94fa719aa",
            "d1abd9ea844b4669aded1500fa3d463d",
            "dd7a3e74367640f3bd6a1aa991861046"
          ]
        },
        "id": "tf9eGYoD4PFH",
        "outputId": "613819cf-7c02-4c67-a953-8b39a0f746ce"
      },
      "source": [
        "#  tokenizer = loadBert() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2bbfa24853846c4b2a1b81b9dedbb8c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "844047a7c3ce43fea4ddede2d1e9d0a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68a094714eb34bf4b910fd8202fa72f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "74d8296c29824624b98c7cf4fdb38dac",
            "157f7cdb25174ac092e6cece32398b2f",
            "ed45036fbf57429fac491863027099a5",
            "f3367423b72b4c70879f3a7305ebf9d5",
            "80857f4794584a5bb335e26178ae18b7",
            "390fe4974dff42aebebda4cd33e67288",
            "6c16ec2bc47b4db79f41e4b42dff60bf",
            "5342847e1d5844f0b897f7ad0db80b6e",
            "cce37e0a05cb42f5973c807ba701d67e",
            "44d8aa8db5c548af98c1d32cc4fe987a",
            "fc6c7599793948018315f9c7ba202620",
            "4654e69daeae4ecbb8825c9ca1b33b86",
            "3d0cb292e5424ddb8c63d21c4e233b82",
            "3db426ac887f44b2938acb307b9705bc",
            "d04cabf8221f404dba3cb6cbcd25edc6",
            "94c6619d6ce546c48f0cdacbea6eb8bf"
          ]
        },
        "id": "Da025T6_7gMN",
        "outputId": "effafff1-14a5-49fe-bbbf-54cd590b33fb"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig, BertForNextSentencePrediction\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForNextSentencePrediction.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74d8296c29824624b98c7cf4fdb38dac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cce37e0a05cb42f5973c807ba701d67e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForNextSentencePrediction(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyNSPHead(\n",
              "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axEfzRG57qFG",
        "outputId": "9d7e3e4c-e2f7-47be-b570-73af9942c290"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "cls.seq_relationship.weight                                 (2, 768)\n",
            "cls.seq_relationship.bias                                       (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHS_ADwL8ffu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yivE0HbR8nPW"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AiqepPEhR3B"
      },
      "source": [
        "def recover_checkpoint(tune_checkpoint_dir, model_name=None):\n",
        "    if tune_checkpoint_dir is None or len(tune_checkpoint_dir) == 0:\n",
        "        return model_name\n",
        "    # Get subdirectory used for Huggingface.\n",
        "    subdirs = [\n",
        "        os.path.join(tune_checkpoint_dir, name)\n",
        "        for name in os.listdir(tune_checkpoint_dir)\n",
        "        if os.path.isdir(os.path.join(tune_checkpoint_dir, name))\n",
        "    ]\n",
        "    # There should only be 1 subdir.\n",
        "    assert len(subdirs) == 1, subdirs\n",
        "    return subdirs[0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXiMYzpZv54K"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score,train_test_split\n",
        "import random\n",
        "import numpy as np\n",
        "def trainingProcess(config,df,checkpoint_dir=None):\n",
        "      print(\"************************************************************\")\n",
        "      print(\"Training Process begins now...........\")\n",
        "      optimizer = AdamW(model.parameters(),\n",
        "                    lr = config[\"lr\"], \n",
        "                    # lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                  )\n",
        "\n",
        "      if checkpoint_dir:\n",
        "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "        model_state, optimizer_state = torch.load(checkpoint)\n",
        "        model.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "\n",
        "      print(\"Step 1: tokenize\")\n",
        "\n",
        "    # performTokonize\n",
        "      max_seq_length = 256\n",
        "      input_ids=[]\n",
        "      token_type_ids = []\n",
        "\n",
        "      for index, row in df.iterrows(): \n",
        "          encoded_dict = tokenizer.encode_plus(row['req1'],row['req2'],max_length=256, pad_to_max_length=True, truncation=True)\n",
        "          input_ids.append(encoded_dict['input_ids'])\n",
        "          token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "      input_ids = torch.tensor(input_ids)#,dtype=torch.long)\n",
        "      token_type_ids = torch.tensor(token_type_ids)#,dtype=torch.long)\n",
        "\n",
        "      print(\"Step 2: split into train validation\")\n",
        "    # trainTestSplit\n",
        "      from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "      labels = df.Label.values\n",
        "      dataset = TensorDataset(input_ids, token_type_ids, torch.tensor(labels))\n",
        "      train_size = int(.9 * len(dataset))\n",
        "      val_size = len(dataset) - train_size\n",
        "      train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "      print('{:>5,} training samples'.format(train_size))\n",
        "      print('{:>5,} validation samples'.format(val_size))\n",
        "    # return train_dataset, val_dataset\n",
        "\n",
        "      print(\"Step 3: data loading\")\n",
        "  # dataloading\n",
        "      from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "      batch_size=int(config[\"batch_size\"])\n",
        "      # batch_size=32\n",
        "\n",
        "    ## Create the DataLoaders for our training and validation sets.\n",
        "    ## We'll take training samples in random order. \n",
        "      train_dataloader = DataLoader(\n",
        "              train_dataset,  # The training samples.\n",
        "              sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "              batch_size = batch_size # Trains with this batch size.\n",
        "          )\n",
        "\n",
        "    ## For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "      validation_dataloader = DataLoader(\n",
        "              val_dataset, # The validation samples.\n",
        "              sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "              batch_size = batch_size # Evaluate with this batch size.\n",
        "          )\n",
        "    # return train_dataloader, validation_dataloader\n",
        "\n",
        "      print(\"Step 4: set scheduler and traning epochs\")\n",
        "  # trainingepochs\n",
        "      from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "      epochs = int(config[\"num_epochs\"])\n",
        "      # epochs = 3\n",
        "\n",
        "    # #Total number of training steps is [number of batches] x [number of epochs]. \n",
        "    # #(Note that this is not the same as the number of training samples).\n",
        "      total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # #Create the learning rate scheduler.\n",
        "      scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                              num_training_steps = total_steps)\n",
        "    # return epochs,total_steps, scheduler\n",
        "\n",
        "\n",
        "      print(\"Step 5: Training the model begins now\")\n",
        "  # training\n",
        "\n",
        "  # def training(train_dataloader,validation_dataloader, epochs, total_steps, scheduler):\n",
        "      # #Help by\n",
        "      ##https://github.com/Shivampanwar/Bert-text-classification/blob/master/bert_language_model_with_sequence_classification.ipynb\n",
        "\n",
        "      ## This training code is based on the `run_glue.py` script here:\n",
        "      ## https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "      # #Set the seed value all over the place to make this reproducible.\n",
        "      seed_val = 42\n",
        "\n",
        "      random.seed(seed_val)\n",
        "      np.random.seed(seed_val)\n",
        "      torch.manual_seed(seed_val)\n",
        "      torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "      # #We'll store a number of quantities such as training and validation loss, \n",
        "      # #validation accuracy, and timings.\n",
        "      training_stats = []\n",
        "\n",
        "      # #Measure the total training time for the whole run.\n",
        "      total_t0 = time.time()\n",
        "\n",
        "      # #Store our loss and accuracy for plotting\n",
        "      train_loss_set = []\n",
        "\n",
        "      total_step = len(train_dataloader)\n",
        "\n",
        "      # #For each epoch...\n",
        "      for epoch_i in range(0, epochs):\n",
        "          \n",
        "          # ========================================\n",
        "          #               Training\n",
        "          # ========================================\n",
        "          \n",
        "          # #Perform one full pass over the training set.\n",
        "\n",
        "          print(\"\")\n",
        "          print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "          print('Training...')\n",
        "\n",
        "          # #Measure how long the training epoch takes.\n",
        "          t0 = time.time()\n",
        "\n",
        "          # #Reset the total loss for this epoch.\n",
        "          total_train_loss = 0\n",
        "\n",
        "          # #Put the model into training mode. Don't be mislead--the call to \n",
        "          # ##`train` just changes the *mode*, it doesn't *perform* the training.\n",
        "          # #`dropout` and `batchnorm` layers behave differently during training\n",
        "          # #vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "          model.train()\n",
        "\n",
        "          # #For each batch of training data...\n",
        "          for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "              # #Progress update every 40 batches.\n",
        "              if step % 40 == 0 and not step == 0:\n",
        "                  # #Calculate elapsed time in minutes.\n",
        "                  elapsed = format_time(time.time() - t0)\n",
        "                  \n",
        "                  # #Report progress.\n",
        "                  print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "              # #Unpack this training batch from our dataloader. \n",
        "              ##\n",
        "              # #As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "              # #`to` method.\n",
        "              ##\n",
        "              # #`batch` contains three pytorch tensors:\n",
        "              # #  [0]: input ids \n",
        "              # #  [1]: attention masks\n",
        "              # #  [2]: labels \n",
        "              b_input_ids = batch[0].to(device)\n",
        "              b_token_type_ids = batch[1].to(device)\n",
        "              b_labels = batch[2].to(device)\n",
        "\n",
        "              # #Always clear any previously calculated gradients before performing a\n",
        "              # #backward pass. PyTorch doesn't do this automatically because \n",
        "              # #accumulating the gradients is \"convenient while training RNNs\". \n",
        "              # #(source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "              model.zero_grad()        \n",
        "\n",
        "              # #Perform a forward pass (evaluate the model on this training batch).\n",
        "              # ##The documentation for this `model` function is here: \n",
        "              # #https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "              # #It returns different numbers of parameters depending on what arguments\n",
        "              # #arge given and what flags are set. For our useage here, it returns\n",
        "              # #the loss (because we provided labels) and the \"logits\"--the model\n",
        "              # #outputs prior to activation.\n",
        "              ##loss,logits = model(b_input_ids, \n",
        "              #                     token_type_ids=b_token_type_ids, attention_mask=None, next_sentence_label=b_labels)\n",
        "              \n",
        "              output = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=None, next_sentence_label=b_labels)\n",
        "              loss, logits=output[:2]\n",
        "              \n",
        "              ##print(output[0])\n",
        "              ##input(\"hit enter\")\n",
        "              ##loss = output[0]\n",
        "              # #Accumulate the training loss over all of the batches so that we can\n",
        "              # #calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "              # #single value; the `.item()` function just returns the Python value \n",
        "              # #from the tensor.\n",
        "              total_train_loss += loss.item()\n",
        "              ##train_loss_set.append(loss.item())  \n",
        "\n",
        "              # #Perform a backward pass to calculate the gradients.\n",
        "              loss.backward()\n",
        "\n",
        "              # #Clip the norm of the gradients to 1.0.\n",
        "              # #This is to help prevent the \"exploding gradients\" problem.\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "              # #Update parameters and take a step using the computed gradient.\n",
        "              # #The optimizer dictates the \"update rule\"--how the parameters are\n",
        "              # #modified based on their gradients, the learning rate, etc.\n",
        "              optimizer.step()\n",
        "\n",
        "              # #Update the learning rate.\n",
        "              scheduler.step()\n",
        "\n",
        "          # #Calculate the average loss over all of the batches.\n",
        "          avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "          \n",
        "          # #Measure how long this epoch took.\n",
        "          training_time = format_time(time.time() - t0)\n",
        "\n",
        "          print(\"\")\n",
        "          print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "          print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "              \n",
        "          # #========================================\n",
        "          #  #             Validation\n",
        "          # #========================================\n",
        "          # #After the completion of each training epoch, measure our performance on\n",
        "          # #our validation set.\n",
        "\n",
        "          print(\"\")\n",
        "          print(\"Running Validation...\")\n",
        "\n",
        "          t0 = time.time()\n",
        "\n",
        "          # #Put the model in evaluation mode--the dropout layers behave differently\n",
        "          # #during evaluation.\n",
        "          model.eval()\n",
        "\n",
        "          # #Tracking variables \n",
        "          total_eval_accuracy = 0\n",
        "          total_eval_loss = 0\n",
        "          nb_eval_steps = 0\n",
        "\n",
        "          # #Evaluate data for one epoch\n",
        "          for batch in validation_dataloader:\n",
        "              \n",
        "              # #Unpack this training batch from our dataloader. \n",
        "              ##\n",
        "              # #As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "              # #the `to` method.\n",
        "              # #\n",
        "              # #`batch` contains three pytorch tensors:\n",
        "              # #  [0]: input ids \n",
        "              # #  [1]: attention masks\n",
        "              # #  [2]: labels \n",
        "              b_input_ids = batch[0].to(device)\n",
        "              b_token_type_ids = batch[1].to(device)\n",
        "              b_labels = batch[2].to(device)\n",
        "              \n",
        "              # #Tell pytorch not to bother with constructing the compute graph during\n",
        "              # #the forward pass, since this is only needed for backprop (training).\n",
        "              with torch.no_grad():        \n",
        "\n",
        "                  # #Forward pass, calculate logit predictions.\n",
        "                  # #token_type_ids is the same as the \"segment ids\", which \n",
        "                  # #differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                  # #The documentation for this `model` function is here: \n",
        "                  # #https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                  # #Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                  # #values prior to applying an activation function like the softmax.\n",
        "                  # #(loss, logits) = model(b_input_ids, \n",
        "                  #  #                token_type_ids=b_token_type_ids, attention_mask=None, next_sentence_label=b_labels)\n",
        "                  \n",
        "                  outputs = model(b_input_ids, \n",
        "                                  token_type_ids=b_token_type_ids, attention_mask=None, next_sentence_label=b_labels)\n",
        "                  \n",
        "                  #_, #preds = torch.max(outputs, dim=1)\n",
        "                  loss, logits = outputs[:2]\n",
        "\n",
        "              # #Accumulate the validation loss.\n",
        "              total_eval_loss += loss.item()\n",
        "                  \n",
        "              # #Move logits and labels to CPU\n",
        "              logits = logits.detach().cpu().numpy()\n",
        "              label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "              # #Calculate the accuracy for this batch of test sentences, and\n",
        "              # #accumulate it over all batches.\n",
        "              total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "              \n",
        "\n",
        "          # #Report the final accuracy for this validation run.\n",
        "          avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "          print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "          # #Calculate the average loss over all of the batches.\n",
        "          avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "          \n",
        "          # #Measure how long the validation run took.\n",
        "          validation_time = format_time(time.time() - t0)\n",
        "          \n",
        "          print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "          print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "           \n",
        "          # report to tune end of each epoch\n",
        "          # tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
        "\n",
        "\n",
        "        #  hyperParameter Tuning \n",
        "          with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n",
        "               path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "               torch.save(\n",
        "                (model.state_dict(), optimizer.state_dict()), path)\n",
        "            \n",
        "          tune.report(eval_acc=avg_val_accuracy)\n",
        "\n",
        "        #  hyperParameter Tuning   \n",
        "\n",
        "          # #Record all statistics from this epoch.\n",
        "          training_stats.append(\n",
        "              {\n",
        "                  'epoch': epoch_i + 1,\n",
        "                  'Training Loss': avg_train_loss,\n",
        "                  'Valid. Loss': avg_val_loss,\n",
        "                  'Valid. Accur.': avg_val_accuracy,\n",
        "                  'Training Time': training_time,\n",
        "                  'Validation Time': validation_time\n",
        "              }\n",
        "          )\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Training complete!\")\n",
        "\n",
        "      print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "      # return training_stats\n",
        "\n",
        "  # draw_table\n",
        "      # Display floats with two decimal places.\n",
        "      pd.set_option('precision', 2)\n",
        "\n",
        "      # Create a DataFrame from our training statistics.\n",
        "      df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "      # Use the 'epoch' as the row index.\n",
        "      df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "      # A hack to force the column headers to wrap.\n",
        "      #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "      # Display the table.\n",
        "      print(df_stats)\n",
        "\n",
        "\n",
        "  # plot_loss\n",
        "\n",
        "      import matplotlib.pyplot as plt\n",
        "      % matplotlib inline\n",
        "\n",
        "      import seaborn as sns\n",
        "  # def plot_loss(df_stats):\n",
        "        # Use plot styling from seaborn.\n",
        "      sns.set(style='darkgrid')\n",
        "\n",
        "      # Increase the plot size and font size.\n",
        "      sns.set(font_scale=1.5)\n",
        "      plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "      # Plot the learning curve.\n",
        "      plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "      plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "      # Label the plot.\n",
        "      plt.title(\"Training & Validation Loss\")\n",
        "      plt.xlabel(\"Epoch\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.legend()\n",
        "      plt.xticks([1, 2, 3])\n",
        "\n",
        "      plt.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWxWtWgrziVr"
      },
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, \\\n",
        "     f1_score, precision_score, recall_score, roc_auc_score\n",
        "import pickle\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import metrics\n",
        "# def testingProcess(config,df_test):\n",
        "def testingProcess(model,best_bS,df_test):\n",
        "\n",
        "      df=df_test\n",
        "      print(\"Step 6: Testing data loading...................\")\n",
        "# validation\n",
        "\n",
        "# def validation(df):\n",
        "      # Report the number of sentences.\n",
        "      print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "      max_seq_length = 256\n",
        "      input_ids=[]\n",
        "      token_type_ids = []\n",
        "      labels = df.Label.values\n",
        "      print(df.Label.value_counts())\n",
        "\n",
        "      for index, row in df.iterrows(): \n",
        "          #print (row[\"Name\"], row[\"Age\"]) \n",
        "          #print(row['req1'], \" --- \", row['req2'])\n",
        "          #req1,req2 = checkLength((row['req1'],(row['req2'])\n",
        "          encoded_dict = tokenizer.encode_plus(row['req1'],row['req2'],max_length=256, pad_to_max_length=True,truncation=True)\n",
        "          #print(encoded_dict['input_ids'])\n",
        "          #print(encoded_dict['token_type_ids'])\n",
        "          input_ids.append(encoded_dict['input_ids'])\n",
        "          token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "          #break;\n",
        "\n",
        "      input_ids = torch.tensor(input_ids)#,dtype=torch.long)\n",
        "      token_type_ids = torch.tensor(token_type_ids)#,dtype=torch.long)\n",
        "      labels = torch.tensor(labels)\n",
        "    # Set the batch size.  \n",
        "\n",
        "      # batch_size = int(config[\"batch_size\"])\n",
        "      batch_size = best_bS\n",
        "\n",
        "      # batch_size = 32\n",
        "\n",
        "    # Create the DataLoader.\n",
        "      prediction_data = TensorDataset(input_ids, token_type_ids, labels)\n",
        "      prediction_sampler = SequentialSampler(prediction_data)\n",
        "      prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "    # return prediction_dataloader\n",
        "\n",
        "# evaluate\n",
        "      print(\"Step 6: Testing begins\")\n",
        "      test_predictions=[]\n",
        "      s_prediction = []\n",
        "      with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, batch in enumerate(prediction_dataloader):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_token_type_id, b_labels = batch\n",
        "            # Forward pass\n",
        "            \n",
        "            outputs = model(b_input_ids, token_type_ids=b_token_type_id)\n",
        "            # print (outputs)\n",
        "            prediction = torch.argmax(outputs[0],dim=1)\n",
        "            total += b_labels.size(0)\n",
        "            correct+=(prediction==b_labels).sum().item()\n",
        "            test_predictions.append(prediction)\n",
        "            \n",
        "            softmax = torch.nn.Softmax(dim=1)\n",
        "            prob = softmax(outputs[0])\n",
        "            s_prediction.append([t.item() for t in list(prediction)])\n",
        "\n",
        "      flat_list = [item for sublist in s_prediction for item in sublist]\n",
        "      print(correct, total)\n",
        "      print(s_prediction)\n",
        "      print('Test Accuracy of the model on val data is: {} %'.format(100 * correct / total))\n",
        "      accuracy = accuracy_score(df.Label.values, flat_list)\n",
        "      matthews = matthews_corrcoef(df.Label.values, flat_list)\n",
        "      print(\"Accuracy is: \", accuracy, \"      Mathews corrCoef is: \", matthews)\n",
        "      # print(accuracy, matthews)\n",
        "      df['prediction'] = flat_list\n",
        "      # return flat_list, df\n",
        "\n",
        "      # plottingpreds\n",
        "\n",
        "\n",
        "      # def plottingpreds(flat_list):\n",
        "      pred=flat_list\n",
        "\n",
        "      lbl=1\n",
        "      precisions = {}\n",
        "      recalls = {}\n",
        "      f1s = {}\n",
        "      aucrocs = {}\n",
        "\n",
        "      label_name=[0,lbl]\n",
        "      prediction = flat_list\n",
        "      for i in range(len(label_name)):\n",
        "          prediction_ = [1 if pred == i else 0 for pred in prediction]\n",
        "          true_ = [1 if label == i else 0 for label in df.Label.values]\n",
        "          f1s.update({label_name[i]: f1_score(true_, prediction_)})\n",
        "          precisions.update({label_name[i]: precision_score(true_, prediction_)})\n",
        "          recalls.update({label_name[i]: recall_score(true_, prediction_)})\n",
        "          #aucrocs.update({label_name[i]: roc_auc_score(true_, list(t.item() for t in prob[:, i]))})\n",
        "      # metrics_dict = {'accuracy': accuracy, 'matthews coef': matthews, 'precision': precisions, 'recall': recalls, 'f1': f1s}#, 'aucroc': aucrocs}\n",
        "\n",
        "      #pickle.dump(metrics_dict, open('evaluation_metrics', 'wb'))\n",
        "\n",
        "      # cm = plot_confusion_matrix(list(df.Label.values), prediction, label_name, normalize=False,\n",
        "      #                           path='test_confusion_matrix', title='confusion matrix for test dataset')\n",
        "   # plt.savefig('test_confusion_matrix', format='png')\n",
        "  # cm_norm = plot_confusion_matrix(list(df.Label.values), prediction, label_name, normalize=True,\n",
        "  #                           path='test normalized_confusion_matrix', title='normalized confusion matrix for test dataset')\n",
        "  # plt.savefig('test_normalized_confusion_matrix', format='png')\n",
        "      print(\"cm:\",metrics.confusion_matrix(list(df.Label.values), prediction, label_name))\n",
        "      print([[\"TN\",\"FP\"],\n",
        "         [\"FN\",\"TP\"]])\n",
        "\n",
        "  # print('cm',list(df.Label.values))\n",
        "\n",
        "      for i in range(len(label_name)):\n",
        "          print('precision score for %s: %.2f' % (label_name[i], precisions[label_name[i]]))\n",
        "          print('recall score for %s: %.2f' % (label_name[i], recalls[label_name[i]]))\n",
        "          print('f1 score for %s: %.2f' % (label_name[i], f1s[label_name[i]]))\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nejVLiaGlVJk"
      },
      "source": [
        "# def main(df, df_test):\n",
        "# # train_size = [150,300,450,600,750,900,1050,1200,1350,1500,1650,1800,1950,2150]\n",
        "#   # train_size = [300,600,900,1200,1500,1800,2100,2400,2700,3000,3300,3600,3900,4200,4450]\n",
        "# # train_size = [100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1420]\n",
        "#   train_size = [100]\n",
        "#   x = len(df)\n",
        "#   for i in train_size:\n",
        "#       fac = i/x \n",
        "#       df_train, dummy = train_test_split(df,test_size=(1-fac),stratify=df['Label'])\n",
        "#       print('df:',len(df),'df_test:', len(df_test),'dummy:',len(dummy))\n",
        "#       trainingProcess(df_train)\n",
        "#       testingProcess(df_test)\n",
        "#       print(\"*\"*80)\n",
        "#   pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S90cGEjFl0mg",
        "outputId": "73d14d27-5517-4a56-830e-06719225d7c3"
      },
      "source": [
        "# main(df, df_test)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df: 1431 df_test: 361 dummy: 1331\n",
            "************************************************************\n",
            "Training Process begins now...........\n",
            "Step 1: tokenize\n",
            "Step 2: split into train validation\n",
            "   90 training samples\n",
            "   10 validation samples\n",
            "Step 3: data loading\n",
            "Step 4: set scheduler and traning epochs\n",
            "Step 5: Training the model begins now\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:1416: FutureWarning: The `next_sentence_label` argument is deprecated and will be removed in a future version, use `labels` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.28\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.60\n",
            "  Validation Loss: 0.70\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.77\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50\n",
            "  Validation Loss: 0.70\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50\n",
            "  Validation Loss: 0.77\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:12 (h:mm:ss)\n",
            "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
            "epoch                                                                         \n",
            "1               1.28         0.70            0.6       0:00:04         0:00:00\n",
            "2               0.77         0.70            0.5       0:00:04         0:00:00\n",
            "3               0.64         0.77            0.5       0:00:04         0:00:00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Step 6: Testing data loading...................\n",
            "Number of test sentences: 361\n",
            "\n",
            "0    181\n",
            "1    180\n",
            "Name: Label, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 6: Testing begins\n",
            "179 361\n",
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
            "Test Accuracy of the model on val data is: 49.58448753462604 %\n",
            "Accuracy is:  0.49584487534626037       Mathews corrCoef is:  -0.052850826640112356\n",
            "cm: [[  0 181]\n",
            " [  1 179]]\n",
            "[['TN', 'FP'], ['FN', 'TP']]\n",
            "precision score for 0: 0.00\n",
            "recall score for 0: 0.00\n",
            "f1 score for 0: 0.00\n",
            "precision score for 1: 0.50\n",
            "recall score for 1: 0.99\n",
            "f1 score for 1: 0.66\n",
            "********************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Q_XpKvvLS2"
      },
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import ray\n",
        "from ray import tune\n",
        "# from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "def main(num_samples=10):\n",
        "\n",
        "  tokenizer = loadBert() \n",
        "  df, df_test= readFile()\n",
        "\n",
        "  # train_size = [150,300,450,600,750,900,1050,1200,1350,1500,1650,1800,1950,2150]\n",
        "  # train_size = [300,600,900,1200,1500,1800,2100,2400,2700,3000,3300,3600,3900,4200,4450]\n",
        "  # train_size = [100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1420]\n",
        "  train_size = [100]\n",
        "  x = len(df)\n",
        "  for i in train_size:\n",
        "      fac = i/x \n",
        "      df_train, dummy = train_test_split(df,test_size=(1-fac),stratify=df['Label'])\n",
        "      print('df:',len(df),'df_train:',len(df_train),'df_test:', len(df_test),'dummy:',len(dummy))\n",
        "      config = {\n",
        "        \"lr\": tune.loguniform(2e-5, 3e-5, 5e-5),\n",
        "        \"batch_size\": tune.choice([16, 32]),\n",
        "        \"num_epochs\": tune.choice([2, 3, 4])\n",
        "      }\n",
        "      scheduler = PopulationBasedTraining(\n",
        "        time_attr=\"training_iteration\",\n",
        "        metric=\"eval_acc\",\n",
        "        mode=\"max\",\n",
        "        perturbation_interval=2,\n",
        "        hyperparam_mutations={\n",
        "            \"lr\": lambda: tune.loguniform(2e-5, 3e-5, 5e-5).func(None),\n",
        "            \"batch_size\": [16, 32, 64],\n",
        "        })\n",
        "      analysis = tune.run(\n",
        "        tune.with_parameters(trainingProcess, df=df_train),\n",
        "        resources_per_trial={\n",
        "            \"cpu\": 1,\n",
        "            \"gpu\": 1\n",
        "        },\n",
        "        config=config,\n",
        "        metric=\"eval_acc\",\n",
        "        mode=\"max\",\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler\n",
        "        # ,\n",
        "        # name=\"tune_transformer_pbt\"\n",
        "      )\n",
        "      best_config = analysis.get_best_config(metric=\"eval_acc\", mode=\"max\")\n",
        "      print(best_config)\n",
        "      best_checkpoint = recover_checkpoint(\n",
        "      analysis.get_best_trial(metric=\"eval_acc\",\n",
        "                            mode=\"max\").checkpoint.value)\n",
        "      print(best_checkpoint)\n",
        "      best_model = BertForNextSentencePrediction.from_pretrained(\n",
        "      best_checkpoint).to(\"cuda\")\n",
        "      # to debug the status of the ray tune temporary test process is commentted\n",
        "      # testingProcess(best_model,best_batch_size,df_test)\n",
        "      print(\"*\"*80)\n",
        "  pass\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "MmteqJ_C6Buj",
        "outputId": "59750e00-5dc7-4a17-e285-0006d5b25d56"
      },
      "source": [
        "main()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "1431 361\n",
            "df: 1431 df_train: 100 df_test: 361 dummy: 1331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-3a19d743d5e7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m# ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# name=\"tune_transformer_pbt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mexport_formats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_formats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0mmax_failures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_failures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 restore=restore)\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ignoring some parameters passed into tune.run.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, run, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, trial_dirname_creator, loggers, log_to_file, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, export_formats, max_failures, restore)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0;34m\"checkpointable function. You can specify checkpoints \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \"within your trainable function.\")\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_identifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_identifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/experiment.py\u001b[0m in \u001b[0;36mregister_if_needed\u001b[0;34m(cls, run_object)\u001b[0m\n\u001b[1;32m    301\u001b[0m                              \u001b[0;34m\"\\n-If the error is typing-related, try removing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                              \"the type annotations and try again.\")\n\u001b[0;32m--> 303\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_msg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ray.cloudpickle.dumps(<class 'ray.tune.function_runner.wrap_function.<locals>.ImplicitFunc'>) failed.\nTo check which non-serializable variables are captured in scope, re-run the ray script with 'RAY_PICKLE_VERBOSE_DEBUG=1'. Other options: \n-Try reproducing the issue by calling `pickle.dumps(trainable)`. \n-If the error is typing-related, try removing the type annotations and try again."
          ]
        }
      ]
    }
  ]
}